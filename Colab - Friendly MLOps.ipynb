{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Colab - Friendly MLOps.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/timsetsfire/friendly-mlops/blob/main/Colab%20-%20Friendly%20MLOps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLxOyJ2xMrlL"
      },
      "source": [
        "# Friendly MLOps with DRUM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OUbruxUMrlM"
      },
      "source": [
        "Considering the [10k Diabetes dataset](./data/readmissions_train.csv) and a number of pretrained models, we'll get our hands dirty by \n",
        "\n",
        "* Using DRUM for performance testing of models\n",
        "* Using DRUM for validation of models \n",
        "* Using DRUM to get a REST API endpoint\n",
        "* Show ease of swapping models out (different framewokrs - H2O GLM, DataRobot LGMB, Python Catboost, Python XGBoost\n",
        "* Instrument humility rules\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I41nRtO7wwfm"
      },
      "source": [
        "## Grab the `friendly-mlops` repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsGg4qVaw056",
        "outputId": "a9a647f8-0ee6-45b5-9ea9-9a6ae16f3a45"
      },
      "source": [
        "!git clone https://github.com/timsetsfire/friendly-mlops.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'friendly-mlops'...\n",
            "remote: Enumerating objects: 67, done.\u001b[K\n",
            "remote: Counting objects: 100% (67/67), done.\u001b[K\n",
            "remote: Compressing objects: 100% (67/67), done.\u001b[K\n",
            "remote: Total 67 (delta 30), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (67/67), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5F8TBQYUw5sR"
      },
      "source": [
        "## Install requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSCMiQA4w8Lx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12b0caa6-5c8f-4677-d1d8-fe005709495e"
      },
      "source": [
        "!pip install -U -r /content/friendly-mlops/colab_requirements.txt -q"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 20.1MB 1.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 276kB 52.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 296kB 51.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.4MB 53.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 25.9MB 118kB/s \n",
            "\u001b[K     |████████████████████████████████| 7.0MB 56.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 66.0MB 55kB/s \n",
            "\u001b[K     |████████████████████████████████| 8.7MB 27.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 148.9MB 81kB/s \n",
            "\u001b[K     |████████████████████████████████| 153kB 57.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 276kB 50.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 17.7MB 210kB/s \n",
            "\u001b[K     |████████████████████████████████| 788kB 45.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 58.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 7.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 9.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 9.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 808kB 52.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 12.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 552kB 55.8MB/s \n",
            "\u001b[?25h  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for memory-profiler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for progress (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for strictyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for uwsgi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.18.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 0.25.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement pandas>=1.0.4, but you'll have pandas 0.25.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmbcpdmS3zOK"
      },
      "source": [
        "## Restart KERNEL!\n",
        "\n",
        "go to Runtime -> Restart Runtime\n",
        "\n",
        "This ensures we used the version so libraries we just installed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykjnP6-ZMrlM"
      },
      "source": [
        "# Models\n",
        "\n",
        "Several models have been been trained in advanced and are available in the model folder of this repo.  Each models is has been trained to predict the probability of readmission for a given patient.  Several frameworks have been used to train aforementioned models to highlight versatility of DRUM when it comes to ease of usage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dd-bFSGIyFyN",
        "outputId": "27466387-5232-4feb-802e-2d16780dab6e"
      },
      "source": [
        "! ls -l /content/friendly-mlops/models"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 20\n",
            "drwxr-xr-x 2 root root 4096 Mar 29 17:00 catboost\n",
            "drwxr-xr-x 2 root root 4096 Mar 29 17:00 datarobot\n",
            "drwxr-xr-x 2 root root 4096 Mar 29 17:00 h2o\n",
            "drwxr-xr-x 2 root root 4096 Mar 29 17:00 xgboost\n",
            "drwxr-xr-x 2 root root 4096 Mar 29 17:00 xgboost-with-humility\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDUoPRIxzF7T"
      },
      "source": [
        "There are a lot of [frameworks](https://github.com/datarobot/datarobot-user-models#built-in-model-support)  and models which DRUM supports natively, but for those which DRUM doesn't support of these shelf, we'll just need to create some custom hooks so DRUM.  In this example, we'll highlight some very simple custom hooks, and will provide links to more complex examples.\n",
        "\n",
        "Those (Python and R) hooks include\n",
        "* `init`\n",
        "* `load_model`\n",
        "* `read_input_data`\n",
        "* `transform` aka preprocessing\n",
        "* `score`\n",
        "* `post_process`\n",
        "* `unstructured_predict` - scoring arbitrary data and returning arbitrary output.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DP6_K3Pryaz8"
      },
      "source": [
        "# Validation\n",
        "\n",
        "You can validate the model on a set of various checks. It is highly recommended to run these checks, as they are performed in DataRobot before the model can be deployed.\n",
        "\n",
        "List of checks:\n",
        "\n",
        "* null values imputation - each feature of the provided dataset is set to missing and fed to the model.\n",
        "\n",
        "This takes some time to run but will not be pursued.  __It is highly recommended to run these checks__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4C7MQpC0ZZp"
      },
      "source": [
        "# %%sh\n",
        "# drum validation --code-dir ./friendly-mlops/models/xgboost \\\n",
        "# --input ./friendly-mlops/data/readmissions_test.csv \\\n",
        "# --target-type binary \\\n",
        "# --positive-class-label True \\\n",
        "# --negative-class-label False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UugxJupUyc7E"
      },
      "source": [
        "# Performance Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNggovVD1_aD",
        "outputId": "dc75cefd-66aa-422c-cd3c-fbbfeb410ade"
      },
      "source": [
        "%%sh\n",
        "drum perf-test --code-dir ./friendly-mlops/models/xgboost \\\n",
        "--input ./friendly-mlops/data/readmissions_test.csv \\\n",
        "--target-type binary \\\n",
        "--positive-class-label True \\\n",
        "--negative-class-label False \\\n",
        "--verbose"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Detected perf-test mode\n",
            "DRUM performance test\n",
            "Model:      /content/friendly-mlops/models/xgboost\n",
            "Data:       /content/friendly-mlops/data/readmissions_test.csv\n",
            "# Features: 48\n",
            "Preparing test data...\n",
            "Running drum using: [drum server --code-dir /content/friendly-mlops/models/xgboost --address localhost:38911 --logging-level warning --show-perf --target-type binary --positive-class-label True --negative-class-label False]\n",
            "\n",
            "\n",
            "\n",
            "Running test case with timeout: 600\n",
            "Running test case: 264 bytes - 1 samples, 100 iterations\n",
            "Running test case with timeout: 600\n",
            "Running test case: 0.1MB - 396 samples, 50 iterations\n",
            "Running test case with timeout: 600\n",
            "Running test case: 10MB - 39685 samples, 5 iterations\n",
            "Running test case with timeout: 600\n",
            "Running test case: 50MB - 198428 samples, 1 iterations\n",
            "Test is done stopping drum server\n",
            "\n",
            "  size      samples   iters    min     avg     max    used (MB)   total physical\n",
            "                                                                       (MB)     \n",
            "================================================================================\n",
            "264 bytes         1     100   0.088   0.092   0.112     200.668        13021.047\n",
            "0.1MB           396      50   0.109   0.113   0.123     201.125        13021.047\n",
            "10MB          39685       5   1.624   1.645   1.705     440.402        13021.047\n",
            "50MB         198428       1   7.880   7.880   7.880    1323.605        13021.047\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "tput: terminal attributes: No such device or address\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4p0zDG-VWJP"
      },
      "source": [
        "# Batch Scoring with DRUM\n",
        "<a id=\"setup_complete\"></a>\n",
        "\n",
        "At this point our model has been written to disk and we want to start making predictions with it.  To do this, we'll leverage DRUM and it's ability to natively handle our scikit learn model, all we need to do is tell DRUM where it resides as well as the data we wish to score.  \n",
        "\n",
        "There are a lot of frameworks which DRUM supports nateively, but for those which DRUM doesn't support of these shelf, we'll just need to create some custom hooks so DRUM.  In this example, we'll highlight some very simple custom hooks, and will provide links to more complex examples.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_OOeqEx6hqH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7ebeb55-1075-4c27-a9b0-cbf4890f302b"
      },
      "source": [
        "%%sh \n",
        "drum score --code-dir ./friendly-mlops/models/xgboost \\\n",
        "--input ./friendly-mlops/data/readmissions_test.csv \\\n",
        "--output ./friendly-mlops/data/predictions.csv \\\n",
        "--target-type binary \\\n",
        "--positive-class-label True \\\n",
        "--negative-class-label False \\"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "  defaults = yaml.load(f)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLQnWJw_MrlU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c7a19e47-71d5-488d-9bbd-ea5acecf52fd"
      },
      "source": [
        "import pandas as pd\n",
        "pd.read_csv(\"/content/friendly-mlops/data/predictions.csv\").head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>True</th>\n",
              "      <th>False</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.532502</td>\n",
              "      <td>0.467498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.716724</td>\n",
              "      <td>0.283276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.655804</td>\n",
              "      <td>0.344196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.616853</td>\n",
              "      <td>0.383147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.816218</td>\n",
              "      <td>0.183782</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       True     False\n",
              "0  0.532502  0.467498\n",
              "1  0.716724  0.283276\n",
              "2  0.655804  0.344196\n",
              "3  0.616853  0.383147\n",
              "4  0.816218  0.183782"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmS971iweH6t"
      },
      "source": [
        "# Serving via API with DRUM\n",
        "\n",
        "Batch scoring can be very useful, but the utility DRUM offers does not stop there.  We can also leverage DRUM to serve our model as a RESTful API endpoint.  The only thing that changes is the way we will structure the command - using the `server` mode instead of `score` model.  We'll also need to provide an address which is NOT in use.  \n",
        "\n",
        "When starting the server, we'll use `subprocess.Popen` so we may interact with the server in this notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7BrHC1gYjHD"
      },
      "source": [
        "import subprocess\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import yaml\n",
        "import time\n",
        "import os\n",
        "from pprint import pprint"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crlRTOHcMrld"
      },
      "source": [
        "run_inference_server = [\"drum\",\n",
        "              \"server\",\n",
        "              \"--code-dir\",\"/content/friendly-mlops/models/xgboost\", \n",
        "              \"--address\", \"0.0.0.0:6789\", \n",
        "              \"--show-perf\",\n",
        "              \"--target-type\", \"binary\",\n",
        "              \"--positive-class-label\", \"True\",\n",
        "              \"--negative-class-label\", \"False\",\n",
        "              \"--logging-level\", \"info\",\n",
        "              \"--show-stacktrace\",\n",
        "              \"--verbose\",\n",
        "              # \"--production\", \n",
        "              # \"--max-workers\", \"5\"\n",
        "              ]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWvksr_sYlEr"
      },
      "source": [
        "inference_server = subprocess.Popen(run_inference_server, stdout=subprocess.PIPE)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZfzEEPZ9kZG"
      },
      "source": [
        "# !sudo service nginx status"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peFenY-leJo3"
      },
      "source": [
        "## Ping the Server to make sure it is running"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmh7SRfQVnTU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a91af6b-ecb9-48e8-e434-9a70bc5f00a0"
      },
      "source": [
        "## confirm the server is running\n",
        "time.sleep(5) ## snoozing before pinging the server to give it time to actually start\n",
        "print('check status')\n",
        "requests.request(\"GET\", \"http://0.0.0.0:6789/\").content"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "check status\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'{\"message\":\"OK\"}\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOsaTgXOeNMG"
      },
      "source": [
        "## Send data to server for inference\n",
        "\n",
        "The request must provide our dataset as form data.  In order to do so, we'll create a simple python function to pass the data over appropriately.  We'll leverage the same function in our simple flask app a little later.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ-sZcHMYmRx"
      },
      "source": [
        "def score(data, port = \"6789\"):\n",
        "    b_buf = BytesIO()\n",
        "    b_buf.write(data.to_csv(index=False).encode(\"utf-8\"))\n",
        "    b_buf.seek(0)\n",
        "  \n",
        "    url = \"http://localhost:{}/predict/\".format(port)\n",
        "    files = [\n",
        "        ('X', b_buf)\n",
        "    ]\n",
        "    response = requests.request(\"POST\", url, files = files, timeout=None, verify=False)\n",
        "    return response"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjdKXUcUWUXq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a042c95d-de76-49fb-e639-cb85f4d890ec"
      },
      "source": [
        "# %%timeit\n",
        "scoring_data = pd.read_csv(\"./friendly-mlops/data/readmissions_test.csv\")\n",
        "predictions = score(scoring_data).json() ## score entire dataset but only show first 5 records\n",
        "pd.DataFrame(predictions[\"predictions\"]).head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>True</th>\n",
              "      <th>False</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.532502</td>\n",
              "      <td>0.467498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.716724</td>\n",
              "      <td>0.283276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.655804</td>\n",
              "      <td>0.344196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.616853</td>\n",
              "      <td>0.383147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.816218</td>\n",
              "      <td>0.183782</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       True     False\n",
              "0  0.532502  0.467498\n",
              "1  0.716724  0.283276\n",
              "2  0.655804  0.344196\n",
              "3  0.616853  0.383147\n",
              "4  0.816218  0.183782"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a20HW9uMrl1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2444296-7790-433f-c855-f4f817007636"
      },
      "source": [
        "requests.request(\"POST\", \"http://0.0.0.0:6789/shutdown\").content"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'Server shutting down...'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG3HHHnR942W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e75799b-6dc6-4b21-8f4f-22f3dbd9834c"
      },
      "source": [
        "inference_server.terminate()\n",
        "inference_server.stdout.readlines()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[b'Detected REST server mode - this is an advanced option\\n',\n",
              " b'Detected /content/friendly-mlops/models/xgboost/custom.py .. trying to load hooks\\n',\n",
              " b'\\x1b[32m \\x1b[0m\\n',\n",
              " b'\\x1b[32m \\x1b[0m\\n',\n",
              " b'\\x1b[32m============================================================\\x1b[0m\\n',\n",
              " b'\\x1b[32mComponent: prediction_server\\x1b[0m\\n',\n",
              " b'\\x1b[32mLanguage:  Python\\x1b[0m\\n',\n",
              " b'\\x1b[32mOutput:\\x1b[0m\\n',\n",
              " b'\\x1b[32m------------------------------------------------------------\\x1b[0m\\n',\n",
              " b' * Serving Flask app \"datarobot_drum.drum.server\" (lazy loading)\\n',\n",
              " b' * Environment: production\\n',\n",
              " b'   WARNING: This is a development server. Do not use it in a production deployment.\\n',\n",
              " b'   Use a production WSGI server instead.\\n',\n",
              " b' * Debug mode: off\\n',\n",
              " b'run_predictor_total:\\n',\n",
              " b'\\tsec: min: 0.13; avg: 0.13; max: 0.13\\n',\n",
              " b'\\x1b[32m------------------------------------------------------------\\x1b[0m\\n',\n",
              " b'\\x1b[32mRuntime:    13.6 sec\\x1b[0m\\n',\n",
              " b'\\x1b[32mNR outputs: 0\\x1b[0m\\n',\n",
              " b'\\x1b[32m============================================================\\x1b[0m\\n',\n",
              " b'\\x1b[32m \\x1b[0m\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fXsO0ZQ9wGn"
      },
      "source": [
        "# %%sh\n",
        "# nginx -s stop\n",
        "# sudo service nginx status"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1STyzxDR6Gnf"
      },
      "source": [
        "## Humility\n",
        "\n",
        "Whether or not your model can handle missing values for features and new levels for categorical data is a seperate issue from what to do when missing values and new levels occur within the data. \n",
        "\n",
        "Machine learning models are not infaliable.  They can learn biases and get things wrong.  We'll consider adding a layer of humility to our model as they reside in production by introducing actions to take in certain instances.  \n",
        "\n",
        "* Should you model make predictions as usual when an outlying input is observed?  \n",
        "\n",
        "* Your model can handle new levels of categoricals, but should you let it??  Should you throw and exception or provide a prediction but log the observation?\n",
        "\n",
        "* In the case of prediction, how should you handle uncertain predictions (classification) or unreasonably high or low predictions (regression)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgiJXvZG8LY9"
      },
      "source": [
        "## Humility on 10K Diabetes\n",
        "\n",
        "To introduce humility to our XGBoost model, a simple class was written to be involked in our custom.py script, specifically, we'll have a humility check that runs on input features within the `transform` hook, and a humility check that happens on the predictions within the `post_processing` hook.  \n",
        "\n",
        "For example, in our humility rules for 10k diabetes, we'll consider a rule for \n",
        "* outlying input for `time_in_hospital`\n",
        "* `prediction` override\n",
        "* known / unknown levels for `race`\n",
        "\n",
        "```\n",
        "- feature: race\n",
        "  rule: categorical  \n",
        "  known_values:\n",
        "    - Caucasian\n",
        "    - AfricanAmerican\n",
        "    - Hispanic\n",
        "    - Other\n",
        "    - Asian\n",
        "    - \"?\"\n",
        "  action:\n",
        "    key: do nothing\n",
        "    value: null \n",
        "- feature: time_in_hospital\n",
        "  rule: outlying_input\n",
        "  bounds:\n",
        "    lower_bound: 1\n",
        "    upper_bound: 100\n",
        "  action:\n",
        "    key: do nothing\n",
        "    value: null\n",
        "- prediction_column: \"True\"\n",
        "  bounds:\n",
        "    lower_bound: 0.48\n",
        "    upper_bound: 0.52\n",
        "  rule: uncertain_prediction\n",
        "  action: \n",
        "    key: override_prediction\n",
        "    value: 0.0\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5evvn68_6F5j",
        "outputId": "17029bb8-54f4-4a41-df44-4c83d491e790"
      },
      "source": [
        "%%sh\n",
        "drum score \\\n",
        "--code-dir ./friendly-mlops/models/xgboost-with-humility \\\n",
        "--input ./friendly-mlops/data/readmissions_test_humility.csv \\\n",
        "--target-type binary \\\n",
        "--positive-class-label True \\\n",
        "--negative-class-label False \\"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         True     False\n",
            "0    0.609406  0.390594\n",
            "1    0.716724  0.283276\n",
            "2    0.647538  0.352462\n",
            "3    0.595122  0.404878\n",
            "4    0.816218  0.183782\n",
            "..        ...       ...\n",
            "495  0.586178  0.413822\n",
            "496  0.458597  0.541403\n",
            "497  0.466822  0.533178\n",
            "498  0.478825  0.521175\n",
            "499  0.349466  0.650534\n",
            "\n",
            "[500 rows x 2 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "  defaults = yaml.load(f)\n",
            "2021-03-28 18:29:37,382 WARNING KnownCategories:  new levels detected for feature age: ['[99-103)']\n",
            "2021-03-28 18:29:37,386 WARNING KnownCategories:  new levels detected for feature race: [nan]\n",
            "2021-03-28 18:29:37,389 WARNING OutlyingInput:  input not in [1, 100] for feature time_in_hospital\n",
            "2021-03-28 18:29:37,543 WARNING UncertainPrediction:  uncertain prediction made\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIGQMPjgMrl3"
      },
      "source": [
        "## Value Prop\n",
        "\n",
        "One may ask, what is the benefit to be had here?  Well, first of, there is not need for me to write an api to get the model up and running.  Second, DRUM allows me to abstract the framework away (provided I'm using one that is natively supported, or I can write enough python so that DRUM understands how to hook up to the model.  \n",
        "\n",
        "For example, I could hot swap models as I see fit (see exampels in `./friendly-mlops/models`)\n",
        "\n",
        "While we will run through several other frameworks with in `score` you can bet they are supported in `server` mode as well!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHGKKPfNMrl4"
      },
      "source": [
        "#### H2O GLM Mojo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPxTpC-NMrl4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e81394f2-cbd8-4631-e265-4fbd2f811584"
      },
      "source": [
        "%%sh\n",
        "drum score \\\n",
        "--code-dir ./friendly-mlops/models/h2o \\\n",
        "--input ./friendly-mlops/data/readmissions_test.csv \\\n",
        "--target-type binary \\\n",
        "--positive-class-label True \\\n",
        "--negative-class-label False \\"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        FALSE      TRUE\n",
            "0    0.713687  0.286313\n",
            "1    0.791950  0.208050\n",
            "2    0.451245  0.548755\n",
            "3    0.632735  0.367265\n",
            "4    0.757495  0.242505\n",
            "..        ...       ...\n",
            "495  0.591182  0.408818\n",
            "496  0.657564  0.342436\n",
            "497  0.699272  0.300728\n",
            "498  0.324734  0.675266\n",
            "499  0.302756  0.697244\n",
            "\n",
            "[500 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35pX5I94Mrl7"
      },
      "source": [
        "#### DataRobot Light GBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz6CNMITMrl7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3da026a3-2cea-4ae6-af8f-6cc4ea9acb5e"
      },
      "source": [
        "%%sh\n",
        "drum score \\\n",
        "--code-dir ./friendly-mlops/models/datarobot \\\n",
        "--input ./friendly-mlops/data/readmissions_test.csv \\\n",
        "--target-type binary \\\n",
        "--positive-class-label True \\\n",
        "--negative-class-label False \\"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         True     False\n",
            "0    0.335276  0.664724\n",
            "1    0.293130  0.706870\n",
            "2    0.493023  0.506977\n",
            "3    0.353853  0.646147\n",
            "4    0.212991  0.787009\n",
            "..        ...       ...\n",
            "495  0.547511  0.452489\n",
            "496  0.346488  0.653512\n",
            "497  0.550543  0.449457\n",
            "498  0.520717  0.479283\n",
            "499  0.732253  0.267747\n",
            "\n",
            "[500 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsanmxC-Mrl9"
      },
      "source": [
        "#### Python Catboost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myCq6e63Mrl-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dfaff5d-77ef-4996-cb2b-04f64043cee5"
      },
      "source": [
        "%%sh\n",
        "drum score \\\n",
        "--code-dir ./friendly-mlops/models/catboost \\\n",
        "--input ./friendly-mlops/data/readmissions_test.csv \\\n",
        "--target-type binary \\\n",
        "--positive-class-label True \\\n",
        "--negative-class-label False \\"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         True     False\n",
            "0    0.735228  0.264772\n",
            "1    0.735228  0.264772\n",
            "2    0.419437  0.580563\n",
            "3    0.591693  0.408307\n",
            "4    0.735228  0.264772\n",
            "..        ...       ...\n",
            "495  0.591693  0.408307\n",
            "496  0.591693  0.408307\n",
            "497  0.486772  0.513228\n",
            "498  0.419437  0.580563\n",
            "499  0.419437  0.580563\n",
            "\n",
            "[500 rows x 2 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "  defaults = yaml.load(f)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b64jAKbMrmD"
      },
      "source": [
        "# Monitoring Deployments\n",
        "\n",
        "What follows will require a DataRobot account.  You can get a trial account at [https://www.datarobot.com/trial/](https://www.datarobot.com/trial/)\n",
        "\n",
        "Also, JDK 11 or 12 will be required.\n",
        "\n",
        "The main idea: we'll will start an agent service locally.  This agent will be monitoring a spooler.  The spooler could be something as simple as local file system, or a little more realistic like a message broker (pubsub, rabbitmq, sqs).  \n",
        "\n",
        "Once, this agent is spun up locally, we'll enable a few environment variables to let DRUM know that there is an agent present and that it needs to buffer data to defined spool.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tfg4efhHMrmE"
      },
      "source": [
        "## Getting the monitoring agents\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3859XOYMrmE"
      },
      "source": [
        "Currently - have to go in through the [UI](https://app2.datarobot.com/account/developer-tools) to grab the agents "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc7dZ5Ti4n-W"
      },
      "source": [
        "import datarobot as dr"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsnraGL9MrmF"
      },
      "source": [
        "token = \"token\"\n",
        "endpoint = \"https://app2.datarobot.com\"\n",
        "## connect to DataRobot platform with python client. \n",
        "client = dr.Client(token, \"{}/api/v2\".format(endpoint))\n",
        "mlops_agents_tb = client.get(\"mlopsInstaller\")\n",
        "with open(\"/content/friendly-mlops/mlops-agent.tar.gz\", \"wb\") as f:\n",
        "    f.write(mlops_agents_tb.content)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6BU9DbfMrmL"
      },
      "source": [
        "!tar -xf /content/friendly-mlops/mlops-agent.tar.gz -C .\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCvCVHTyMrmO"
      },
      "source": [
        "## Configuring the Agent\n",
        "\n",
        "When we'll configure the agent, we just need to define the DataRobot MLOPS location, our api token.  By default, the agent will expect the data to be spooled on the local file system.  Specifically, the default location will be `/tmp/ta` so we just need to make sure that location exists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmhhI_2_MrmO"
      },
      "source": [
        "!mkdir -p /tmp/ta"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDVCJw4qMrmS"
      },
      "source": [
        "agents_dir = \"/content/datarobot_mlops_package-7.1.6\"\n",
        "with open(r'{}/conf/mlops.agent.conf.yaml'.format(agents_dir)) as file:\n",
        "    documents = yaml.load(file, Loader=yaml.FullLoader)\n",
        "## configure the loaction of the mlops instance with which we'll communcate\n",
        "documents['mlopsUrl'] = endpoint\n",
        "# Set your API token\n",
        "documents['apiToken'] = token\n",
        "## write the configuration back to disk\n",
        "with open('../{}/conf/mlops.agent.conf.yaml'.format(agents_dir), \"w\") as f:\n",
        "    yaml.dump(documents, f)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdaHl8XGMrmU"
      },
      "source": [
        "## Start the Agent Service\n",
        "\n",
        "Checking to make sure we can start up the agents service.  \n",
        "\n",
        "This will require a JDK - tested with 11 and 12"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXqlGPhVMrmU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d849aaa-d316-499f-97b5-8147369238d8"
      },
      "source": [
        "## run agents service\n",
        "subprocess.call(\"{}/bin/start-agent.sh\".format(agents_dir))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ED-Oqh8MrmX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9d3f39b-f91b-4712-b69a-f5f9f4ae7fc8"
      },
      "source": [
        "## check status\n",
        "check = subprocess.Popen([\"../{}/bin/status-agent.sh\".format(agents_dir)], stdout=subprocess.PIPE)\n",
        "print(check.stdout.readlines())\n",
        "check.terminate()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[b'DataRobot MLOps-Agent is running as a service.\\n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyOhPs-6MrmZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51eee7e0-4016-44fd-e45a-dbbcb9aed5bc"
      },
      "source": [
        "## check log to see that the agent connected to DR MLOps\n",
        "check = subprocess.Popen([\"cat\", \"../{}/logs/mlops.agent.log\".format(agents_dir)], stdout=subprocess.PIPE)\n",
        "for line in check.stdout.readlines():\n",
        "    print(line)\n",
        "check.terminate()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'2021-03-29 17:44:38,774 INFO  com.datarobot.mlops.agent.config.channels.YamlBuilder        [] - Found spooler of type FILESYSTEM\\n'\n",
            "b'2021-03-29 17:44:38,781 INFO  com.datarobot.mlops.agent.config.channels.YamlBuilder        [] - Setting directory = /tmp/ta\\n'\n",
            "b'2021-03-29 17:44:38,781 INFO  com.datarobot.mlops.agent.config.channels.YamlBuilder        [] - Setting CHANNEL_NAME = filesystem\\n'\n",
            "b'2021-03-29 17:44:38,783 INFO  com.datarobot.mlops.agent.AgentRunner                        [] - verifySSL: true\\n'\n",
            "b'2021-03-29 17:44:39,275 INFO  com.datarobot.mlops.common.client.MLOpsClient                [] - Connecting to https://app2.datarobot.com/api/v2/version/\\n'\n",
            "b\"2021-03-29 17:44:39,847 INFO  com.datarobot.mlops.common.client.MLOpsClient                [] - DataRobot Server API Version found: '2.24'\\n\"\n",
            "b'2021-03-29 17:44:39,849 INFO  com.datarobot.mlops.common.client.MLOpsClient                [] - Connecting to https://app2.datarobot.com/api/v2/version/\\n'\n",
            "b\"2021-03-29 17:44:40,103 INFO  com.datarobot.mlops.common.client.MLOpsClient                [] - DataRobot Server API Version found: '2.24'\\n\"\n",
            "b\"2021-03-29 17:44:40,104 INFO  com.datarobot.mlops.agent.Agent                              [] - DataRobot server at 'https://app2.datarobot.com' is reachable.\\n\"\n",
            "b'2021-03-29 17:44:40,104 INFO  com.datarobot.mlops.agent.Agent                              [] - DataRobot Monitoring Agent will process 100 records at a time at most.\\n'\n",
            "b'2021-03-29 17:44:40,106 INFO  com.datarobot.mlops.agent.AgentRunner                        [] - Creating new agent channel\\n'\n",
            "b'2021-03-29 17:44:40,107 INFO  com.datarobot.mlops.agent.AgentRunner                        [] - Initializing agent channel\\n'\n",
            "b\"2021-03-29 17:44:40,123 INFO  com.datarobot.mlops.common.spooler.filesystem.FSRecordSpooler [] - Agent starting from spool file 'null' format: 'byte_array'\\n\"\n",
            "b'2021-03-29 17:44:40,130 INFO  com.datarobot.mlops.agent.AgentRunner                        [] - Initialized\\n'\n",
            "b'2021-03-29 17:44:40,131 INFO  com.datarobot.mlops.agent.AgentRunner                        [] - Listing channels:\\n'\n",
            "b'\\tChannel Name: filesystem, Channel Type: FILESYSTEM\\n'\n",
            "b'\\n'\n",
            "b'2021-03-29 17:44:40,133 INFO  com.datarobot.mlops.agent.AgentRunner                        [] - Running agent as service process pid and hostname [995@df7515738889]\\n'\n",
            "b'2021-03-29 17:51:57,731 INFO  com.datarobot.mlops.agent.aggregator.Aggregator              [] - 1 DEPLOYMENT_STATS record(s) got sent to DataRobot server about deployment - 606212ed8532c93289b08bf6\\n'\n",
            "b\"2021-03-29 17:51:57,765 INFO  com.datarobot.mlops.agent.aggregator.PredictionsDataAggregator [] - Posting '100' prediction data rows, payload size: 40401 bytes\\n\"\n",
            "b'2021-03-29 17:51:59,873 INFO  com.datarobot.mlops.agent.aggregator.PredictionsDataAggregator [] - Finished posting 100 prediction data rows, time: 2107 msec\\n'\n",
            "b'2021-03-29 17:51:59,873 INFO  com.datarobot.mlops.agent.aggregator.Aggregator              [] - 1 PREDICTIONS_DATA record(s) got sent to DataRobot server about deployment - 606212ed8532c93289b08bf6\\n'\n",
            "b'2021-03-29 17:52:15,070 INFO  com.datarobot.mlops.agent.AgentRunner                        [] - MLOps agent runner shutdown in progress...\\n'\n",
            "b'2021-03-29 17:52:15,073 INFO  com.datarobot.mlops.agent.aggregator.PendingRecordsSupervisor [] - Flushing remaining records...\\n'\n",
            "b'2021-03-29 17:52:15,073 INFO  com.datarobot.mlops.agent.aggregator.PendingRecordsSupervisor [] - Records flushed.\\n'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpKEu8LsMrmb"
      },
      "source": [
        "## DataRobot MLOps - Deploying External Model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzhVEIIhMrmb"
      },
      "source": [
        "To communication with DataRobot MLOps, with need to MLOps python client installed which came in the downloaded tarball"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDk1PZv6Mrmc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f29619b9-e790-4848-c0f2-6f58edbac6a3"
      },
      "source": [
        "!pip install /content/datarobot_mlops_*/lib/datarobot_mlops-*.whl -q"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |██▌                             | 10kB 26.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 20kB 31.5MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 30kB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 40kB 15.8MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 51kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 61kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 71kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 81kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 92kB 10.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 102kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 112kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 122kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 8.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 27.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.3MB 27.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 10.6MB/s \n",
            "\u001b[31mERROR: botocore 1.20.39 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U73bULPOMrme"
      },
      "source": [
        "from datarobot.mlops.mlops import MLOps\n",
        "from datarobot.mlops.common.enums import OutputType\n",
        "from datarobot.mlops.connected.client import MLOpsClient\n",
        "from datarobot.mlops.common.exception import DRConnectedException\n",
        "from datarobot.mlops.constants import Constants"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnC0LZIFMrmg"
      },
      "source": [
        "DEPLOYMENT_NAME=\"10 Diabetes Readmissions Prediction\"\n",
        "TRAINING_DATA = '/content/friendly-mlops/data/readmissions_train.csv'"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZO6QToQMrmi"
      },
      "source": [
        "model_info = {\n",
        "        \"name\": \"10K Diabetes\",\n",
        "        \"modelDescription\": {\n",
        "            \"description\": \"prediction price of home\"\n",
        "        },\n",
        "        \"target\": {\n",
        "            \"type\": \"Binary\",\n",
        "            \"name\": \"readmitted\",\n",
        "            \"classNames\": [\"True\", \"False\"],\n",
        "            \"predictionThreshold\": 0.5\n",
        "        }\n",
        "}"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLwKEkJFF7Xp"
      },
      "source": [
        ""
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz3coM_7Mrml",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dae44190-299c-46bf-8098-15088703989a"
      },
      "source": [
        "# Create connected client\n",
        "mlops_client = MLOpsClient(endpoint, token)\n",
        "\n",
        "# Add training_data to model configuration\n",
        "print(\"Uploading training data - {}. This may take some time...\".format(TRAINING_DATA))\n",
        "dataset_id = mlops_client.upload_dataset(TRAINING_DATA)\n",
        "print(\"Training dataset uploaded. Catalog ID {}.\".format(dataset_id))\n",
        "model_info[\"datasets\"] = {\"trainingDataCatalogId\": dataset_id}\n",
        "\n",
        "# Create the model package\n",
        "print('Create model package')\n",
        "model_pkg_id = mlops_client.create_model_package(model_info)\n",
        "model_pkg = mlops_client.get_model_package(model_pkg_id)\n",
        "model_id = model_pkg[\"modelId\"]\n",
        "\n",
        "# Deploy the model package\n",
        "print('Deploy model package')\n",
        "deployment_id = mlops_client.deploy_model_package(model_pkg[\"id\"],\n",
        "                                                            DEPLOYMENT_NAME)\n",
        "\n",
        "# Enable data drift tracking\n",
        "print('Enable feature drift')\n",
        "enable_feature_drift = TRAINING_DATA is not None\n",
        "mlops_client.update_deployment_settings(deployment_id, target_drift=True,\n",
        "                                                  feature_drift=enable_feature_drift)\n",
        "_ = mlops_client.get_deployment_settings(deployment_id)\n",
        "\n",
        "print(\"\\nDone.\")\n",
        "print(\"DEPLOYMENT_ID=%s, MODEL_ID=%s\" % (deployment_id, model_id))\n",
        "\n",
        "DEPLOYMENT_ID = deployment_id\n",
        "MODEL_ID = model_id"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploading training data - /content/friendly-mlops/data/readmissions_train.csv. This may take some time...\n",
            "Training dataset uploaded. Catalog ID 606212cae6c8dc4a6cc990bb.\n",
            "Create model package\n",
            "Deploy model package\n",
            "Enable feature drift\n",
            "\n",
            "Done.\n",
            "DEPLOYMENT_ID=606212ed8532c93289b08bf6, MODEL_ID=606212ec38c12f8c852260e5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k96KiRFiMrmn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec9e2c08-23a9-46ce-e721-835eb8dc235d"
      },
      "source": [
        "from IPython.core.display import display, HTML\n",
        "link = \"{}/deployments/{}/overview\".format(endpoint,deployment_id)\n",
        "# display(HTML(\"\"\"<a href=\"{link}\">{link}</a>\"\"\".format( link=link )))\n",
        "print(link)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://app2.datarobot.com/deployments/606212ed8532c93289b08bf6/overview\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_sIji-jleSr"
      },
      "source": [
        "# Adding Monitoring with MLOps Monitoring Agents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbbfRWU1Mrmp"
      },
      "source": [
        "## Monitoring With DRUM\n",
        "\n",
        "There are a few addition parameters we should set for the command line utility, or we may just create environment variables, and allow the drum utility to pick up the details from there.  \n",
        "\n",
        "```\n",
        "  --monitor             Monitor predictions using DataRobot MLOps. True or\n",
        "                        False. (env: MONITOR).Monitoring can not be used in\n",
        "                        unstructured mode.\n",
        "  --deployment-id DEPLOYMENT_ID\n",
        "                        Deployment id to use for monitoring model predictions\n",
        "                        (env: DEPLOYMENT_ID)\n",
        "  --model-id MODEL_ID   MLOps model id to use for monitoring predictions (env:\n",
        "                        MODEL_ID)\n",
        "  --monitor-settings MONITOR_SETTINGS\n",
        "                        MLOps setting to use for connecting with the MLOps\n",
        "                        Agent (env: MONITOR_SETTINGS)\n",
        "```\n",
        "For today, we'll set environment variables to add monitoring. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu23gamNMrmq"
      },
      "source": [
        "os.environ[\"MONITOR\"] = \"True\"\n",
        "os.environ[\"DEPLOYMENT_ID\"] = deployment_id\n",
        "os.environ[\"MODEL_ID\"] = model_id\n",
        "os.environ[\"MONITOR_SETTINGS\"] = \"spooler_type=filesystem;directory=/tmp/ta;max_files=5;file_max_size=1045876000\""
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gs6kK8PKMrmr"
      },
      "source": [
        "run_inference_server = [\"drum\",\n",
        "              \"server\",\n",
        "              \"--code-dir\",\"friendly-mlops/models/xgboost-with-humility\", \n",
        "              \"--address\", \"0.0.0.0:43210\", \n",
        "              \"--show-perf\",\n",
        "              \"--target-type\", \"binary\",\n",
        "              \"--positive-class-label\", \"True\",\n",
        "              \"--negative-class-label\", \"False\",\n",
        "              \"--logging-level\", \"info\",\n",
        "              \"--show-stacktrace\",\n",
        "#               \"--verbose\"\n",
        "              ]"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkbK6OKbMrmt"
      },
      "source": [
        "inference_server_with_monitoring = subprocess.Popen(run_inference_server, stdout=subprocess.PIPE)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72S5ic_sMrmv"
      },
      "source": [
        "predictions = score(\n",
        "    pd.read_csv(\"/content/friendly-mlops/data/readmissions_test.csv\").head(100),\n",
        "    \"43210\")"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQA_TvN3Mrmx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2c7f349e-0cea-4476-b49e-4bb2982bc8e9"
      },
      "source": [
        "pd.DataFrame(predictions.json()[\"predictions\"]).head()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>True</th>\n",
              "      <th>False</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.532502</td>\n",
              "      <td>0.467498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.716724</td>\n",
              "      <td>0.283276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.655804</td>\n",
              "      <td>0.344196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.616853</td>\n",
              "      <td>0.383147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.816218</td>\n",
              "      <td>0.183782</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       True     False\n",
              "0  0.532502  0.467498\n",
              "1  0.716724  0.283276\n",
              "2  0.655804  0.344196\n",
              "3  0.616853  0.383147\n",
              "4  0.816218  0.183782"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LPPW7qsMrm0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aeb48f1-c877-425a-f332-173b87aac341"
      },
      "source": [
        "requests.post(\"http://localhost:43210/shutdown/\").content"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'Server shutting down...'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDZ48oQFMrm3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f83a6a1f-f770-40de-e222-56dec266f37b"
      },
      "source": [
        "subprocess.call(\"../{}/bin/stop-agent.sh\".format(agents_dir))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAM_HvAiMrm5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62650c15-207b-4982-b056-79f19c406ce7"
      },
      "source": [
        "## check that agent is stopped \n",
        "check = subprocess.Popen([\"../{}/bin/status-agent.sh\".format(agents_dir)], stdout=subprocess.PIPE)\n",
        "print(check.stdout.readlines())\n",
        "check.terminate()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[b'DataRobot MLOps-Agent is running as a service.\\n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o_bqcGCMrnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7559519-9641-4084-fa7e-83916dcd17a4"
      },
      "source": [
        "deployment = dr.Deployment.get(deployment_id)\n",
        "deployment.get_service_stats()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ServiceStats(606212ec38c12f8c852260e5 | 2021-03-22 18:00:00+00:00 - 2021-03-29 18:00:00+00:00)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m5-5VUIMrnC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa50347c-3f7a-4112-f093-914a8a1d80c5"
      },
      "source": [
        "service_stats = deployment.get_service_stats()\n",
        "service_stats.metrics"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cacheHitRatio': 0,\n",
              " 'executionTime': 115.118503570557,\n",
              " 'medianLoad': 0,\n",
              " 'numConsumers': 1,\n",
              " 'peakLoad': 1,\n",
              " 'responseTime': 0,\n",
              " 'serverErrorRate': 0,\n",
              " 'slowRequests': 0,\n",
              " 'totalPredictions': 100,\n",
              " 'totalRequests': 1,\n",
              " 'userErrorRate': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Vff7CRdcbhb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}